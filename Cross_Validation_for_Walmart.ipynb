{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross Validation for Walmart.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PEzqHm2u9XKBdoZsoZ8CZilajpbLn4CE",
      "authorship_tag": "ABX9TyMQ0a0b45wBaQpd7RgE7lBo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaidhyesh1/walmart-assignment/blob/main/Cross_Validation_for_Walmart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo7-tdxNKeld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f4df45-d137-450e-f0e6-82af1503523a"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "#Initialization of the training and testing datasets\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/walmart/model.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/walmart/val.csv')\n",
        "column_names = df_train.columns \n",
        "\n",
        "#Checking the counts of element in each class\n",
        "print(df_train['default'].value_counts())\n",
        "#It is found that there are 90k samples of class 0 and 4k samples of class 1. The data is not balanced\n",
        "\n",
        "#MinMaxScaler normalizes the columns from 0 to 1\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "df_train_without_default = df_train.drop(['default'], axis=1)\n",
        "preprocess_df = scaler.fit_transform(df_train_without_default)\n",
        "normalized_df_train = pd.DataFrame(preprocess_df,columns=column_names[:-1])\n",
        "df_train_final = pd.concat([normalized_df_train, df_train[['default']]], axis=1)\n",
        "print(\"\\n\")\n",
        "print('Normalized data')\n",
        "print(df_train_final.head())\n",
        "\n",
        "#Normalizing test data for future usage\n",
        "df_test_without_default = df_test.drop(['default'], axis=1)\n",
        "preprocess_df_test = scaler.fit_transform(df_test_without_default)\n",
        "X_test = pd.DataFrame(preprocess_df_test, columns=column_names[:-1])\n",
        "y_test = df_test.default\n",
        "\n",
        "#Running PCA for 2 components and plotting it for better idea of the data\n",
        "# pca = PCA(n_components=2)\n",
        "# principal_components = pca.fit_transform(normalized_df_train)\n",
        "# principal_df = pd.DataFrame(data = principal_components, columns = ['X axis', 'Y axis'])\n",
        "# final_principal_df = pd.concat([principal_df, df_train[['default']]], axis=1)\n",
        "# print(\"\\n\")\n",
        "# print('Data after PCA')\n",
        "# print(final_principal_df.head())\n",
        "\n",
        "#Plotting the data on the graph\n",
        "# fig = plt.figure(figsize = (8,8))\n",
        "# ax = fig.add_subplot(1,1,1) \n",
        "# ax.set_xlabel('X axis', fontsize = 15)\n",
        "# ax.set_ylabel('Y axis', fontsize = 15)\n",
        "# ax.set_title('PCA Analysis', fontsize = 20)\n",
        "# targets = [0,1]\n",
        "# colors = ['r', 'b']\n",
        "# for target, color in zip(targets,colors):\n",
        "#     indicesToKeep = final_principal_df['default'] == target\n",
        "#     ax.scatter(final_principal_df.loc[indicesToKeep, 'X axis']\n",
        "#                , final_principal_df.loc[indicesToKeep, 'Y axis']\n",
        "#                , c = color\n",
        "#                , s = 50)\n",
        "# ax.legend(targets)\n",
        "# ax.grid()\n",
        "\n",
        "\n",
        "df_zero = df_train_final[df_train_final['default'] == 0] #contains normalized combination of both x and y\n",
        "df_one = df_train_final[df_train_final['default'] == 1]\n",
        "listOfSplitElements = np.array_split(df_zero, 23)\n",
        "\n",
        "for df_zero_subset in listOfSplitElements:\n",
        "  df_to_train = pd.concat([df_zero_subset,df_one])\n",
        "  mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)\n",
        "  mlp.fit(df_to_train.drop(['default'], axis=1),df_to_train.default)\n",
        "  y_pred_mlp = mlp.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred_mlp))\n",
        "#X_train = normalized_df_train\n",
        "#y_train = df_train.default\n",
        "\n",
        "#After analysis we see that even if there are some outliers, the samples are seperable. Therefore running logistic regression\n",
        "# logistic_reg = LogisticRegression(max_iter=500)\n",
        "# logistic_reg.fit(X_train_undersampled,y_train_undersampled)\n",
        "# y_pred_logistic = logistic_reg.predict(X_test)\n",
        "# logistic_results_df = pd.DataFrame(y_pred_logistic)\n",
        "# logistic_results_df.to_csv('/content/drive/MyDrive/Colab Notebooks/walmart/results1.csv',header=False,index=False)\n",
        "# print(\"\\n\")\n",
        "# print(\"Summary for Logisitic Regression\")\n",
        "# print(confusion_matrix(y_test,y_pred_logistic))\n",
        "# print(classification_report(y_test,y_pred_logistic))\n",
        "\n",
        "#Running Neural Networks\n",
        "# mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)\n",
        "# mlp.fit(X_train_undersampled,y_train_undersampled)\n",
        "# y_pred_mlp = mlp.predict(X_test)\n",
        "# mlp_results_df = pd.DataFrame(y_pred_mlp)\n",
        "# mlp_results_df.to_csv('/content/drive/MyDrive/Colab Notebooks/walmart/results2.csv',header=False,index=False)\n",
        "# print(\"\\n\")\n",
        "# print(\"Summary for Neural Networks with 8,8,8 hidden layers\")\n",
        "# print(confusion_matrix(y_test,y_pred_mlp))\n",
        "# print(classification_report(y_test,y_pred_mlp))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    90000\n",
            "1     4000\n",
            "Name: default, dtype: int64\n",
            "\n",
            "\n",
            "Normalized data\n",
            "         A1        A2        A3  ...       A29       A30  default\n",
            "0  0.170467  0.824606  0.338738  ...  0.069506  0.050661        0\n",
            "1  0.454473  0.560757  0.249264  ...  0.069786  0.053635        0\n",
            "2  0.396587  0.669274  0.162738  ...  0.076029  0.051711        0\n",
            "3  0.217509  0.821073  0.261551  ...  0.082634  0.050661        0\n",
            "4  0.071759  0.948517  0.332143  ...  0.069506  0.050661        0\n",
            "\n",
            "[5 rows x 31 columns]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92     10000\n",
            "           1       0.46      0.46      0.46      1500\n",
            "\n",
            "    accuracy                           0.86     11500\n",
            "   macro avg       0.69      0.69      0.69     11500\n",
            "weighted avg       0.86      0.86      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.92     10000\n",
            "           1       0.50      0.45      0.47      1500\n",
            "\n",
            "    accuracy                           0.87     11500\n",
            "   macro avg       0.71      0.69      0.70     11500\n",
            "weighted avg       0.86      0.87      0.87     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.92     10000\n",
            "           1       0.43      0.41      0.42      1500\n",
            "\n",
            "    accuracy                           0.85     11500\n",
            "   macro avg       0.67      0.66      0.67     11500\n",
            "weighted avg       0.85      0.85      0.85     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93     10000\n",
            "           1       0.53      0.34      0.41      1500\n",
            "\n",
            "    accuracy                           0.87     11500\n",
            "   macro avg       0.72      0.65      0.67     11500\n",
            "weighted avg       0.86      0.87      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.92     10000\n",
            "           1       0.49      0.46      0.48      1500\n",
            "\n",
            "    accuracy                           0.87     11500\n",
            "   macro avg       0.70      0.70      0.70     11500\n",
            "weighted avg       0.86      0.87      0.87     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.85      0.89     10000\n",
            "           1       0.39      0.63      0.48      1500\n",
            "\n",
            "    accuracy                           0.82     11500\n",
            "   macro avg       0.66      0.74      0.69     11500\n",
            "weighted avg       0.87      0.82      0.84     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.82      0.88     10000\n",
            "           1       0.36      0.68      0.47      1500\n",
            "\n",
            "    accuracy                           0.80     11500\n",
            "   macro avg       0.65      0.75      0.67     11500\n",
            "weighted avg       0.87      0.80      0.82     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.89      0.91     10000\n",
            "           1       0.43      0.56      0.49      1500\n",
            "\n",
            "    accuracy                           0.85     11500\n",
            "   macro avg       0.68      0.72      0.70     11500\n",
            "weighted avg       0.87      0.85      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93     10000\n",
            "           1       0.55      0.36      0.44      1500\n",
            "\n",
            "    accuracy                           0.88     11500\n",
            "   macro avg       0.73      0.66      0.69     11500\n",
            "weighted avg       0.86      0.88      0.87     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.83      0.88     10000\n",
            "           1       0.35      0.62      0.45      1500\n",
            "\n",
            "    accuracy                           0.80     11500\n",
            "   macro avg       0.64      0.72      0.66     11500\n",
            "weighted avg       0.86      0.80      0.82     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93     10000\n",
            "           1       0.54      0.34      0.42      1500\n",
            "\n",
            "    accuracy                           0.88     11500\n",
            "   macro avg       0.72      0.65      0.67     11500\n",
            "weighted avg       0.86      0.88      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.78      0.85     10000\n",
            "           1       0.32      0.69      0.44      1500\n",
            "\n",
            "    accuracy                           0.77     11500\n",
            "   macro avg       0.63      0.73      0.65     11500\n",
            "weighted avg       0.86      0.77      0.80     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92     10000\n",
            "           1       0.45      0.52      0.48      1500\n",
            "\n",
            "    accuracy                           0.85     11500\n",
            "   macro avg       0.69      0.71      0.70     11500\n",
            "weighted avg       0.86      0.85      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92     10000\n",
            "           1       0.48      0.47      0.48      1500\n",
            "\n",
            "    accuracy                           0.86     11500\n",
            "   macro avg       0.70      0.70      0.70     11500\n",
            "weighted avg       0.86      0.86      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93     10000\n",
            "           1       0.56      0.34      0.42      1500\n",
            "\n",
            "    accuracy                           0.88     11500\n",
            "   macro avg       0.73      0.65      0.68     11500\n",
            "weighted avg       0.86      0.88      0.87     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93     10000\n",
            "           1       0.55      0.39      0.46      1500\n",
            "\n",
            "    accuracy                           0.88     11500\n",
            "   macro avg       0.73      0.67      0.69     11500\n",
            "weighted avg       0.86      0.88      0.87     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93     10000\n",
            "           1       0.55      0.32      0.40      1500\n",
            "\n",
            "    accuracy                           0.88     11500\n",
            "   macro avg       0.73      0.64      0.67     11500\n",
            "weighted avg       0.86      0.88      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92     10000\n",
            "           1       0.47      0.46      0.47      1500\n",
            "\n",
            "    accuracy                           0.86     11500\n",
            "   macro avg       0.70      0.69      0.69     11500\n",
            "weighted avg       0.86      0.86      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92     10000\n",
            "           1       0.47      0.50      0.48      1500\n",
            "\n",
            "    accuracy                           0.86     11500\n",
            "   macro avg       0.70      0.71      0.70     11500\n",
            "weighted avg       0.86      0.86      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92     10000\n",
            "           1       0.46      0.44      0.45      1500\n",
            "\n",
            "    accuracy                           0.86     11500\n",
            "   macro avg       0.69      0.68      0.69     11500\n",
            "weighted avg       0.86      0.86      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93     10000\n",
            "           1       0.54      0.37      0.44      1500\n",
            "\n",
            "    accuracy                           0.88     11500\n",
            "   macro avg       0.72      0.66      0.68     11500\n",
            "weighted avg       0.86      0.88      0.87     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.91     10000\n",
            "           1       0.44      0.53      0.48      1500\n",
            "\n",
            "    accuracy                           0.85     11500\n",
            "   macro avg       0.68      0.72      0.70     11500\n",
            "weighted avg       0.86      0.85      0.86     11500\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.92     10000\n",
            "           1       0.49      0.47      0.48      1500\n",
            "\n",
            "    accuracy                           0.87     11500\n",
            "   macro avg       0.71      0.70      0.70     11500\n",
            "weighted avg       0.86      0.87      0.87     11500\n",
            "\n"
          ]
        }
      ]
    }
  ]
}